=== FAIL: 20251229_185215 ===
Log: build_logs/build_20251229_185215.log
Code: 137

--- DETECTED ERROR PATTERNS ---
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1776:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1795:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1829:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  8 errors generated when compiling for gfx1151.
  failed to execute:/opt/rocm-7.1.1/lib/llvm/bin/clang++  --offload-arch=gfx1151  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c -x hip /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/ck_tiled_fmha_grouped_infer_fp16.hip -o "/app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/ck_tiled_fmha_grouped_infer_fp16.o" -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  [14/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/ck_fmha_test.cu -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/ck_fmha_test.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  [16/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core/arch/amd_buffer_addressing_hip.hpp:29:36: error: use of undeclared identifier 'CK_TILE_BUFFER_RESOURCE_3RD_DWORD'
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core/arch/arch_hip.hpp:36:13: error: macro '__AMDGCN_WAVEFRONT_SIZE__' has been marked as deprecated: compile-time-constant access to the wavefront size will be removed in a future release [-Werror,-Wdeprecated-pragma]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core/arch/arch_hip.hpp:37:12: error: macro '__AMDGCN_WAVEFRONT_SIZE__' has been marked as deprecated: compile-time-constant access to the wavefront size will be removed in a future release [-Werror,-Wdeprecated-pragma]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1726:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1758:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1776:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1795:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1829:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
  8 errors generated when compiling for gfx1151.
  failed to execute:/opt/rocm-7.1.1/lib/llvm/bin/clang++  --offload-arch=gfx1151  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c -x hip /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip -o "/app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.o" -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  [17/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_forward_decoder.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_forward_decoder.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  [18/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_forward_splitk.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_forward_splitk.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc

--- TAIL 50 ---
  [13/481] g++ -MMD -MF /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sddmm.o.d -march=znver5 -mtune=znver5 -O3 -mavx512f -mavx512bw -mavx512vl -mavx512dq -mavx512cd -mavx512vbmi -mavx512vbmi2 -mavx512vnni -mavx512bitalg -mavx512vpopcntdq -mavx512bf16 -pipe -fno-plt -fexceptions -flto=auto -O3 -march=znver5 -mtune=znver5 -fPIC -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/cpu/sddmm.cpp -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sddmm.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C
  [14/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/ck_fmha_test.cu -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/ck_fmha_test.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  [15/481] g++ -MMD -MF /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/autograd/matmul.o.d -march=znver5 -mtune=znver5 -O3 -mavx512f -mavx512bw -mavx512vl -mavx512dq -mavx512cd -mavx512vbmi -mavx512vbmi2 -mavx512vnni -mavx512bitalg -mavx512vpopcntdq -mavx512bf16 -pipe -fno-plt -fexceptions -flto=auto -O3 -march=znver5 -mtune=znver5 -fPIC -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/autograd/matmul.cpp -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/autograd/matmul.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -O3 -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C
  [16/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  FAILED: [code=1] /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.o
  /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  In file included from /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip:17:
  In file included from /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core_hip.hpp:10:
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core/arch/amd_buffer_addressing_hip.hpp:29:36: error: use of undeclared identifier 'CK_TILE_BUFFER_RESOURCE_3RD_DWORD'
     29 |     buffer_resource res{ptr, size, CK_TILE_BUFFER_RESOURCE_3RD_DWORD};
        |                                    ^
  In file included from /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip:17:
  In file included from /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core_hip.hpp:11:
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core/arch/arch_hip.hpp:36:13: error: macro '__AMDGCN_WAVEFRONT_SIZE__' has been marked as deprecated: compile-time-constant access to the wavefront size will be removed in a future release [-Werror,-Wdeprecated-pragma]
     36 | #if defined(__AMDGCN_WAVEFRONT_SIZE__)
        |             ^
  <built-in>:907:141: note: macro marked 'deprecated' here
    907 | #pragma clang deprecated(__AMDGCN_WAVEFRONT_SIZE__, "compile-time-constant access to the wavefront size will be removed in a future release")
        |                                                                                                                                             ^
  In file included from /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip:17:
  In file included from /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core_hip.hpp:11:
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/core/arch/arch_hip.hpp:37:12: error: macro '__AMDGCN_WAVEFRONT_SIZE__' has been marked as deprecated: compile-time-constant access to the wavefront size will be removed in a future release [-Werror,-Wdeprecated-pragma]
     37 |     return __AMDGCN_WAVEFRONT_SIZE__;
        |            ^
  <built-in>:907:141: note: macro marked 'deprecated' here
    907 | #pragma clang deprecated(__AMDGCN_WAVEFRONT_SIZE__, "compile-time-constant access to the wavefront size will be removed in a future release")
        |                                                                                                                                             ^
  In file included from /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip:20:
  In file included from /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/ck_tiled_rand_uniform_kernel_hip.h:9:
  In file included from /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha_hip.hpp:22:
  In file included from /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_convert_dq_hip.hpp:8:
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1726:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
   1726 |         CK_TILE_DEVICE static constexpr void GemmStagedScheduler<0>()
        |                        ^~~~~~
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1758:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
   1758 |         CK_TILE_DEVICE static constexpr void GemmStagedScheduler<1>()
        |                        ^~~~~~
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1776:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
   1776 |         CK_TILE_DEVICE static constexpr void GemmStagedScheduler<2>()
        |                        ^~~~~~
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1795:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
   1795 |         CK_TILE_DEVICE static constexpr void GemmStagedScheduler<3>()
        |                        ^~~~~~
  /app/src/extras/xformers/third_party/composable_kernel_tiled/include/ck_tile/ops/fmha/pipeline/block_fmha_bwd_pipeline_default_policy_hip.hpp:1829:24: error: explicit specialization cannot have a storage class [-Werror,-Wexplicit-specialization-storage-class]
   1829 |         CK_TILE_DEVICE static constexpr void GemmStagedScheduler<4>()
        |                        ^~~~~~
  8 errors generated when compiling for gfx1151.
  failed to execute:/opt/rocm-7.1.1/lib/llvm/bin/clang++  --offload-arch=gfx1151  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c -x hip /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.hip -o "/app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_ck_rand_uniform.o" -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  [17/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_forward_decoder.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_forward_decoder.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
  [18/481] /opt/rocm-7.1.1/bin/hipcc  -I/app/src/extras/xformers/xformers/csrc -I/app/src/extras/xformers/xformers/csrc/attention/hip_fmha -I/app/src/extras/xformers/third_party/composable_kernel_tiled/include -I/tmp/.local/lib/python3.11/site-packages/torch/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/tmp/.local/lib/python3.11/site-packages/torch/include/THH -I/opt/rocm-7.1.1/include -I/usr/include/python3.11 -c -c /app/src/extras/xformers/xformers/csrc/attention/hip_fmha/attention_forward_splitk.hip -o /app/src/extras/xformers/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/hip_fmha/attention_forward_splitk.o -D__HIP_PLATFORM_AMD__=1 -DUSE_ROCM=1 -DHIPBLAS_V2 -fPIC -DCUDA_HAS_FP16=1 -D__HIP_NO_HALF_OPERATORS__=1 -D__HIP_NO_HALF_CONVERSIONS__=1 -DHIP_ENABLE_WARP_SYNC_BUILTINS=1 -O3 -std=c++17 --offload-arch=gfx1151 -U__HIP_NO_HALF_OPERATORS__ -U__HIP_NO_HALF_CONVERSIONS__ -DCK_TILE_FMHA_FWD_FAST_EXP2=1 -fgpu-flush-denormals-to-zero -Werror -Woverloaded-virtual -mllvm -enable-post-misched=0 -mllvm -amdgpu-early-inline-all=true -mllvm -amdgpu-function-calls=false -mllvm -greedy-reverse-local-assignment=1 -DBUILD_PYTHON_PACKAGE -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -fno-gpu-rdc
